---
title: "Graded Exercise 3"
author: "Frieda Krois"
date: "2025-06-05"
output: html_document
fig_caption: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 1: Initializing git (4 Points)

For this whole exercise sheet we will be tracking all our changes to it
in git.

a)  Start by initializing a new R project with git support, called
    `2025-exeRcise-sheet-3`. If you forgot how to do this, you can
    follow this
    [guide](https://malikaihle.github.io/Introduction-RStudio-Git-GitHub/rstudio_project.html).
b)  Commit the files generated by Rstudio.
c)  For all of the following tasks in this exercise sheet we ask you to
    always commit your changes after finishing each subtask e.g. create
    a commit after task *1d*, *1e* etc.

> Note: This applies only to answers that have text or code as their
> answer. If you complete tasks in a different order or forget to commit
> one, this is no problem. If you change your answers you can just
> create multiple commits to track the changes.

d)  Name 2 strengths and 2 weaknesses of git. (Don't forget to create a
    commit after this answer, see *1c*)

***Strengths and weaknesses of git***

**strenghts:**

-   convenient and fast for collaboration

-   version control makes it almost impossible to lose files

**weeknesses:**

-   can be tricky to use (especially in the beginning)

-   requires explicit use (does not work in the background)

e)  Knit this exercise sheet. Some new files will automatically be
    generated when knitting the sheet e.g. the HTML page. Ignore these
    files, as we only want to track the source files themselves. You
    can, but don't need to create a `.gitignore` file. Just do not
    commit these files manually.



## Exercise 2: Putting your Repository on GitHub (3 Points)

For this task you will upload your solution to GitHub.

a)  Create a new repository on GitHub in your account named
    `exeRcise-sheet-3`. Make sure you create a **public repository** so
    we are able to see it for grading. Add the link to the repository
    below: >https://github.com/Friedikr/exeRcise-sheet-3<
b)  Push your code to this new repository by copying and executing the
    snippet on github listed under
    `…or push an existing repository from the command line`.
c)  Regularly push your latest changes to GitHub again and especially do
    so when you are finished with this sheet.



## Exercise 3: Pixar Films (4 Points)

Download the `pixar_films` and `public_response` datasets from the
GitHub repository and track them in git.

Link:
<https://github.com/rfordatascience/tidytuesday/tree/main/data/2025/2025-03-11>

For small datasets like these adding them to git is not a problem.

a)  Load the `pixar_films` dataset into R. Clean the dataset by removing
    films without a title. Inspect the variable `film_rating`. What are
    the possible values and what do they mean? Create a factor variable
    for the film rating. Why is this appropriate?
```{r} 
# load library
library(tidyverse)
```
    
```{r}
# load data
films <- read_csv("data/pixar_films.csv")
head(films)
```

```{r}
# clean dataframe 
films_clean <- films %>%
  filter(!is.na(film), film != "")
```

```{r}
# change variable film rating to factor 
films_clean$film_rating <- factor(
  films_clean$film_rating,
  levels = c("G", "PG"),
  ordered = TRUE
)
```

The possible values are G (Rated G: General audiences - all ages admitted), PG (arental guidance suggested – Some material may not be suitable for children) and not rated. In addition we have three N/A's (missing/ unspecified values). A factor variable is appropriate because a factor is ideal for categorical data — like film ratings — especially when values are from a known, limited set and may have a natural order which is the case here: film_rating represents categories not numeric quantities and we have a fixed set of possible values (here I just take "interesting values" "G" and "PG" into account).


b)  Inspect the film titles manually. Which films form a film series? A
    film series can be identified by a common word in the titles of the
    films, often in conjunction with a number in the title,
    e.g. "Despicable Me" and "Despicable Me 2". Create a dataframe which
    displays a list of the different series with the titles of the films
    and how many films belong to the series. Output the dataframe.
```{r}
library(dplyr)
library(stringr)

# Funktion: Erster sinnvoller Begriff im Titel (außer "The", "A", ...)
get_series_name <- function(title) {
  words <- str_split(tolower(title), "\\s+")[[1]]
  words <- words[!words %in% c("the", "a", "and", "of", "in", "to")]
  words <- words[!str_detect(words, "^[0-9]+$")]
  if (length(words) > 0) return(str_to_title(words[1]))
  return(NA)
}

# Wende Funktion auf saubere Titelliste an
films_series_summary <- films_clean %>%
  mutate(series_name = sapply(film, get_series_name)) %>%
  filter(!is.na(series_name)) %>%
  group_by(series_name) %>%
  filter(n() > 1) %>%
  summarise(
    film_titles = paste0("[", paste0("'", film, "'", collapse = ", "), "]"),
    film_count = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(film_count))

print(films_series_summary, row.names = FALSE)
```


c)  Load the `public_response` dataframe into R. Convert the
    `cinema_score` variable into a factor while ensuring the factor
    levels are defined in ascending order, from the lowest to the
    highest score. Combine `public_response` with the `pixar_films`
    dataset using an appropriate merge variable.
    
```{r}
public_response <- read_csv("data/public_response.csv")
head(public_response)
```
```{r}
# cinema_score in geordneten Faktor umwandeln mit Levels A- < A < A+
levels_ordered <- c("A-", "A", "A+")

public_response$cinema_score <- factor(public_response$cinema_score, 
                                      levels = levels_ordered, 
                                      ordered = TRUE)



#  Merge der beiden Datensätze über die Spalte "film"
combined_data <- merge(films_clean, public_response, by = "film", all = TRUE)

head(combined_data)
```


d)  Choose one of the variables representing the public response and
    create a bar plot for the films belonging to a series. Here are the
    details of the plot:

    -   The film series are represented on the x-axis.
    -   Your chosen public response variable is displayed on the y-axis.
    -   Each film in the series is represented as a separate bar. Bars
        are grouped by film under their respective series on the x-axis.
        Order the bars within a series according to the release date of
        the films.
    -   A title and axis labels for context.
    
    What do you notice when comparing the scores of the films in a
    series? Do you see any patterns?
```{r}
get_series_name <- function(title) {
  words <- str_split(tolower(title), "\\s+")[[1]]
  words <- words[!words %in% c("the", "a", "and", "of", "in", "to")]
  words <- words[!str_detect(words, "^[0-9]+$")]
  if (length(words) > 0) return(str_to_title(words[1]))
  return(NA)
}

# Step 2: Add series_name column
combined_data <- combined_data %>%
  mutate(series_name = sapply(film, get_series_name))

# Step 3: Keep only series with more than one film
combined_data <- combined_data %>%
  group_by(series_name) %>%
  filter(n() > 1) %>%
  ungroup()

# Step 4: Add release order manually (adjust if needed)
combined_data <- combined_data %>%
  mutate(release_order = case_when(
    film == "Toy Story" ~ 1,
    film == "Toy Story 2" ~ 2,
    film == "Toy Story 3" ~ 3,
    film == "Toy Story 4" ~ 4,
    film == "Cars" ~ 1,
    film == "Cars 2" ~ 2,
    film == "Cars 3" ~ 3,
    film == "The Incredibles" ~ 1,
    film == "Incredibles 2" ~ 2,
    film == "Monsters, Inc." ~ 1,
    film == "Monsters University" ~ 2,
    film == "Finding Nemo" ~ 1,
    film == "Finding Dory" ~ 2,
    TRUE ~ NA_real_
  )) %>%
  filter(!is.na(release_order))
```
    
```{r}
ggplot(combined_data, aes(x = factor(release_order), y = rotten_tomatoes)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.6) +
  geom_text(aes(label = film), vjust = -0.5, size = 2.8, angle = 45, hjust = 0) +
  facet_wrap(~ series_name, scales = "free_x") +
  labs(
    title = "Rotten Tomatoes Scores by Pixar Film Series",
    x = "Release Order",
    y = "Rotten Tomatoes Score (%)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 0, hjust = 0.5),
    strip.text = element_text(face = "bold", size = 12),
    plot.margin = margin(t = 10, r = 10, b = 40, l = 10)  # mehr Platz unten
  ) +
  ylim(0, 105) +
  coord_cartesian(clip = "off")

```
    
I notice that in all four series the first film got the highest scores. The following films of the series could not beat the popularity score of the debut film. Especially in Cars there is a big difference between film 1 and 2.



## Exercise 4: Open Analysis (4 points)

This exercise is a bit more open-ended. You can choose any dataset from
[Our World in Data](https://ourworldindata.org/) and analyze it, while
determining the research question yourself.

a)  Go to <https://github.com/owid/owid-datasets/tree/master/datasets>
    and choose a dataset that interests you. You can have a look at
    <https://ourworldindata.org/> to gather some inspiration.
    
b)  Download the dataset and track it in git.
```{r}
data <- read_csv("data/Missing_women_estimates.csv")
head(data)
```

c)  Put the name / title of the dataset and a link to it below.

-   Dataset Name: Missing women estimates (Bongaarts & Guilmoto, 2015)
-   Link: <https://github.com/owid/owid-datasets/tree/master/datasets/Missing%20women%20estimates%20(Bongaarts%20%26%20Guilmoto%2C%202015)>

d)  Come up with a (research) question you want to answer with the data
    and briefly explain why you believe this is an interesting question
    within one sentence. It should be a question that can be answered
    with the dataset and using R.
    
Research topic: The term "missing women" indicates a shortfall in the number of women relative to the expected number of women in a region or country. Missing female births and excess female mortality are calculated based on the difference between observed and expected sex ratios. It is theorized to be caused by sex-selective abortions, female infanticide, and inadequate healthcare and nutrition for female children. Due to that matter I want to reseach the role of China and India when it comes to missing women worldwide. The dataset gives data for China, Indi, World and Rest of the World from 1970 to today in five-year intervals, with projections through to 2050.

Research question: "What role do China and India play in the global pattern of gender-based demographic inequality, as reflected in the distribution of missing women?"


e)  Use R to answer your chosen question. Please limit your analysis to
    the functions and techniques we have covered so far in the course.
    You are **not expected** to use advanced statistical models or
    external packages which haven't been introduced.
```{r}
colnames(data) <- c("Country", "Year", "Missing_Females", "Excess_Deaths", "Missing_Births")

# data wrangling
data_filtered <- data %>%
  select(Country, Year, Missing_Females)

data_wide <- data_filtered %>%
  pivot_wider(names_from = Country, values_from = Missing_Females)

data_wide <- data_wide %>%
  mutate(
    China_Share = China / World,
    India_Share = India / World,
 
  )

share_long <- data_wide %>%
  select(Year, China_Share, India_Share) %>%
  pivot_longer(cols = c(China_Share, India_Share),
               names_to = "Country", values_to = "Share") %>%
  mutate(Country = recode(Country,
                          "China_Share" = "China",
                          "India_Share" = "India",
                        ))
```

    
f)  Create a meaningful plot / figure with the dataset. Make sure to
    provide a figure caption (via the chunk options / Rmarkdown) and
    correctly label the figure.
    
```{r china-india-share, fig.cap="Proportion of missing women from China and India in the global total", fig.align='center'}
# (Hier kommt dein Plot-Code)
ggplot(share_long, aes(x = Year, y = Share, color = Country)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_color_manual(values = c("firebrick", "darkgreen")) +
  labs(
    x = "Jahr",
    y = "Anteil an der Welt insgesamt (%)",
    color = "Land"
  ) +
  theme_minimal(base_size = 14)
```
    
## Final Note

Make sure to push all your commits and changes to GitHub before
submitting the exercise sheet.